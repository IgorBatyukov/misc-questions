## Explain the difference between concurrent and parallel programming in Python. Provide an example of each.

### Concurrent Programming 
Executing multiple tasks at the same time. In Python, concurrency is typically achieved 
using threading or async libraries. Both should be used in IO bound tasks, when the function sends requests to some 
resource and wait for the response. Instead of just simply waiting and blocking the main thread, tasks switch back and 
forth based on availability of resources.

```python
import asyncio
import aiohttp
import time


async def fetch(url):
    async with aiohttp.ClientSession() as session:
        async with session.get(url) as response:
            return await response.text()


async def main():
    url = 'https://www.google.com'
    tasks = [fetch(url) for _ in range(5)]
    results = await asyncio.gather(*tasks)
    return results

start_time = time.time()
asyncio.run(main())

>>> print(f"Execution time: {time.time() - start_time:.2f} seconds")
Execution time: 0.49 seconds
```

```python
import threading
import requests
import time


def fetch(url):
    response = requests.get(url)
    return response.text


url = 'https://www.google.com'
threads = []
start_time = time.time()

for _ in range(5):
    thread = threading.Thread(target=fetch, args=(url,))
    threads.append(thread)
    thread.start()

for thread in threads:
    thread.join()

>>> print(f"Execution time: {time.time() - start_time:.2f} seconds")
Execution time: 0.43 seconds
```

### Parallel Programming 
Executing multiple tasks actually at the same time on different CPU cores or machines. Tasks are executed 
simultaneously. This is achieved through multiprocessing where different tasks run in separate processes, 
each with its own memory space, and the operating system allocates different CPU cores to them. Can used in both IO and
CPU bound tasks. 

```python
import multiprocessing
import requests
import time


def fetch(url):
    response = requests.get(url)
    return response.text


url = 'https://www.google.com'
start_time = time.time()

with multiprocessing.Pool(processes=5) as pool:
    results = pool.map(fetch, [url] * 5)

>>> print(f"Execution time: {time.time() - start_time:.2f} seconds")
Execution time: 0.46 seconds

```

### Synchronous example for the contrast
```python
import requests
import time


def fetch(url):
    response = requests.get(url)
    return response.text


url = 'https://www.google.com'
start_time = time.time()

results = [fetch(url) for _ in range(5)]

>>> print(f"Execution time: {time.time() - start_time:.2f} seconds")
Execution time: 2.00 seconds
```

### GIL and asyncio 
- No Impact from GIL: In the case of asyncio, the GIL is not a concern because asyncio is designed for 
cooperative multitasking rather than preemptive multitasking.
- Single-threaded: The entire operation runs in a single thread. The event loop can switch between coroutines, 
allowing for asynchronous execution without the GIL becoming a bottleneck.
- I/O-bound Tasks: The GIL does not hinder asyncio's performance with I/O-bound tasks, as these tasks typically 
spend a lot of time waiting for external resources (like network responses), allowing other tasks to run in the meantime.

### GIL and threading
- Limited by GIL: In case with threading, although multiple threads are created, but only one thread can execute Python 
bytecode at a time due to the GIL. This means that if the threads are CPU-bound, they won't run in parallel but 
rather compete for the GIL, leading to potential performance bottlenecks.
- I/O-bound Tasks Benefit: If the threads are I/O-bound, the GIL is released during I/O operations. This allows other 
threads to run while one thread is waiting for I/O to complete, making threading suitable for I/O-bound tasks.

### GIL and multiprocessing
- No GIL Limitation: The multiprocessing library creates separate processes, each with its own Python interpreter 
and memory space. Therefore, the GIL does not apply across processes.
- True Parallelism: Each process can run independently on separate CPU cores, enabling true parallel execution 
of CPU-bound tasks. This is especially beneficial for tasks that require heavy computations, as they can fully 
utilize multiple CPU cores without being hindered by the GIL.
- Overhead: However, using multiple processes comes with some overhead due to inter-process communication 
and the need to manage separate memory spaces.
